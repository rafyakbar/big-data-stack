{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df858680-74bb-4ea1-af85-13d44b70b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.measure_time(func, *args, **kwargs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, when, count as spark_count, concat_ws, length, rand, row_number\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def measure_time(func, *args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = func(*args, **kwargs)\n",
    "    end = time.perf_counter()\n",
    "    return result, end - start\n",
    "\n",
    "measure_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ebec01-d0e5-4962-a962-9a7bf0b95fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7fdab9226fc3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>RAID-TRAIN</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7bcf848f6910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RAID-TRAIN\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65f41de-7158-470f-881d-5be8d90ca3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[attack: string, domain: string, features: array<double>, generation: string, id: string, model: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(\"hdfs://namenode:8020/user/raid/filtered_minilm\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e03f8-e75e-4629-90d1-5fe4741d1550",
   "metadata": {},
   "source": [
    "# Total Baris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2426c7bc-e981-4607-8e15-5b237d3e6186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menghitung total jumlah baris...\n",
      "✅ Total baris: 1,869,542 | Waktu: 287.7117 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"Menghitung total jumlah baris...\")\n",
    "total_rows, time_0 = measure_time(lambda: df.count())\n",
    "print(f\"✅ Total baris: {total_rows:,} | Waktu: {time_0:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc6da2b-d537-4a8a-a94c-8fb6bacd0878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[attack: string, domain: string, features: array<double>, generation: string, id: string, model: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.repartition(32)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4001a-8ea9-40c6-920a-f2ddd2c4b7c2",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee09ccc2-c47b-4c0a-bc2c-8092d23b4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Total jumlah baris setelah filter...\n",
      "✅ Total baris: 1,869,542 | Waktu: 287.7117 detik\n"
     ]
    }
   ],
   "source": [
    "print(f\"[1] Total jumlah baris setelah filter...\")\n",
    "print(f\"✅ Total baris: {total_rows:,} | Waktu: {time_0:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e74f80a-6ada-4da2-b653-38a7e95942b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Membuat kolom stratifikasi 'model_domain_attack' ...\n",
      "✅ Kolom stratifikasi dibuat dalam 0.5549 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[2] Membuat kolom stratifikasi 'model_domain_attack' ...\")\n",
    "df_with_strata, strat_time = measure_time(\n",
    "    lambda: df_filtered.withColumn(\n",
    "        \"model_domain_attack\",\n",
    "        concat_ws(\"_\", col(\"model\"), col(\"domain\"), col(\"attack\"))\n",
    "    )\n",
    ")\n",
    "print(f\"✅ Kolom stratifikasi dibuat dalam {strat_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a93e6a-6a0b-418a-a2ca-4f26bf6b1914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[attack: string, domain: string, features: array<double>, generation: string, id: string, model: string, model_domain_attack: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_strata = df_with_strata.repartition(32)\n",
    "df_with_strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4095181e-ec93-492e-8fe3-337043e20a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Menghitung jumlah baris per 'model_domain_attack' ...\n",
      "✅ Selesai dalam 0.1048 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[3] Menghitung jumlah baris per 'model_domain_attack' ...\")\n",
    "df_counts, count_time = measure_time(\n",
    "    lambda: df_with_strata.groupBy(\"model_domain_attack\").agg(spark_count(\"*\").alias(\"total_per_group\"))\n",
    ")\n",
    "print(f\"✅ Selesai dalam {count_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8e0d5a7-28d0-4a89-8b2a-5032ab131382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Gabungkan count ke setiap baris\n",
      "✅ Data berhasil digabung dengan count per grup dalam 0.8707 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[4] Gabungkan count ke setiap baris\")\n",
    "df_joined, join_time = measure_time(\n",
    "    lambda: df_with_strata.join(df_counts, on=\"model_domain_attack\", how=\"inner\")\n",
    ")\n",
    "print(f\"✅ Data berhasil digabung dengan count per grup dalam {join_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167d96f3-209c-4701-94bb-6820bdd3c0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Memberi nomor urut acak dalam setiap grup ...\n",
      "✅ Penomoran selesai dalam 0.1628 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[5] Memberi nomor urut acak dalam setiap grup ...\")\n",
    "window_spec = Window.partitionBy(\"model_domain_attack\").orderBy(rand())\n",
    "df_numbered, number_time = measure_time(\n",
    "    lambda: df_joined.withColumn(\"row_num\", row_number().over(window_spec))\n",
    ")\n",
    "print(f\"✅ Penomoran selesai dalam {number_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e79d51c1-b398-410f-b299-28ddbde91364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Menentukan split berdasarkan 70% per grup ...\n",
      "✅ Split logic selesai dalam 0.1720 detik\n"
     ]
    }
   ],
   "source": [
    "# [6] Tentukan batas 70% → masuk train jika row_num <= 0.7 * total_per_group\n",
    "print(\"[6] Menentukan split berdasarkan 70% per grup ...\")\n",
    "df_with_split, split_time = measure_time(\n",
    "    lambda: df_numbered.withColumn(\n",
    "        \"is_train\",\n",
    "        col(\"row_num\") <= (col(\"total_per_group\") * 0.7)\n",
    "    )\n",
    ")\n",
    "print(f\"✅ Split logic selesai dalam {split_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef01815f-f7de-4e86-bf3b-361dcfcf844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train: 1,308,514 (277.7806 detik) | Test: 561,028 (299.0928 detik)\n"
     ]
    }
   ],
   "source": [
    "# [7] Pisahkan train dan test\n",
    "# train_df = df_with_split.filter(col(\"is_train\")).select(\"model\", \"features\")\n",
    "# test_df = df_with_split.filter(~col(\"is_train\")).select(\"model\", \"features\")\n",
    "\n",
    "train_df = df_with_split.filter(col(\"is_train\")).select(\n",
    "    col(\"generation\").alias(\"text\"),\n",
    "    col(\"model\"),\n",
    "    col(\"features\")\n",
    ")\n",
    "test_df = df_with_split.filter(~col(\"is_train\")).select(\n",
    "    col(\"generation\").alias(\"text\"),\n",
    "    col(\"model\"),\n",
    "    col(\"features\")\n",
    ")\n",
    "\n",
    "train_count, train_count_time = measure_time(lambda: train_df.count())\n",
    "test_count, test_count_time = measure_time(lambda: test_df.count())\n",
    "\n",
    "print(f\"✅ Train: {train_count:,} ({train_count_time:.4f} detik) | Test: {test_count:,} ({test_count_time:.4f} detik)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7830da8f-23a8-42d9-9949-a3b748d954d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.functions import array_to_vector\n",
    "\n",
    "train_df = train_df.withColumn(\"features\", array_to_vector(col(\"features\")))\n",
    "test_df = test_df.withColumn(\"features\", array_to_vector(col(\"features\")))\n",
    "\n",
    "# Opsional: cek tipe kolom\n",
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9e2f1-9b16-49ea-9841-1967c7542ea6",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bb012e0-16ff-49ea-8d54-a7a7d84227d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame[model: string, features: vector],\n",
       " DataFrame[model: string, features: vector])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab3cf4ff-4929-4eec-866a-32fa959a7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membangun pipeline...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline_221e4d4867f7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Pipeline: StringIndexer + LogisticRegression ===\n",
    "print(\"Membangun pipeline...\")\n",
    "\n",
    "# StringIndexer untuk label 'model'\n",
    "string_indexer = StringIndexer(\n",
    "    inputCol=\"model\",\n",
    "    outputCol=\"label\",\n",
    "    handleInvalid=\"error\"\n",
    ")\n",
    "\n",
    "# Logistic Regression langsung pada fitur numerik (384-d)\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    family=\"multinomial\",\n",
    "    regParam=0.01,      # regularisasi ringan\n",
    "    maxIter=100,\n",
    "    tol=1e-6\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[string_indexer, lr])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0fedd58-33db-49b6-a0ef-29dd29c94cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] Melatih model pada train_df...\n",
      "✅ Model berhasil dilatih dalam 4449.0414 detik\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Latih model ---\n",
    "print(\"[14] Melatih model pada train_df...\")\n",
    "model, train_model_time = measure_time(\n",
    "    lambda: pipeline.fit(train_df)\n",
    ")\n",
    "print(f\"✅ Model berhasil dilatih dalam {train_model_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6df37c9-d9ba-43fd-9867-4a0fbf05ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] Menyimpan model ke HDFS: hdfs://namenode:8020/user/raid/model-sbert-lr...\n",
      "✅ Model disimpan dalam 11.7212 detik\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Simpan model ke HDFS ---\n",
    "model_path = \"hdfs://namenode:8020/user/raid/model-sbert-lr\"\n",
    "print(f\"[15] Menyimpan model ke HDFS: {model_path}...\")\n",
    "_, save_time = measure_time(\n",
    "    lambda: model.write().overwrite().save(model_path)\n",
    ")\n",
    "print(f\"✅ Model disimpan dalam {save_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b038104-9d9f-4e5e-abc7-2064c36195e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16] Melakukan prediksi pada test_df...\n",
      "✅ Prediksi selesai dalam 0.0720 detik\n",
      "+--------------------------------------------------+-------+-----+----------+--------------------------------------------------+\n",
      "|                                              text|  model|label|prediction|                                       probability|\n",
      "+--------------------------------------------------+-------+-----+----------+--------------------------------------------------+\n",
      "|Semantic image segmentation is a challenging ta...|chatgpt|  6.0|       0.0|[0.24885451444065831,0.21935424670530035,0.1029...|\n",
      "|In this paper, we propose a novel method for au...|chatgpt|  6.0|       2.0|[0.010559748214373261,0.10451266197741882,0.178...|\n",
      "|The paper \"Paradoxical signaling regulates stru...|chatgpt|  6.0|       3.0|[0.022443762183194833,0.30847734773788044,0.003...|\n",
      "|This paper investigates the asymptotic equivale...|chatgpt|  6.0|       4.0|[0.006597733857336278,0.0341569499689347,0.1562...|\n",
      "|Interactive video object segmentation is a chal...|chatgpt|  6.0|       0.0|[0.26786151991887636,0.21694570431008445,0.0212...|\n",
      "+--------------------------------------------------+-------+-----+----------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Prediksi pada test set ---\n",
    "print(\"[16] Melakukan prediksi pada test_df...\")\n",
    "predictions, predict_time = measure_time(\n",
    "    lambda: model.transform(test_df)\n",
    ")\n",
    "print(f\"✅ Prediksi selesai dalam {predict_time:.4f} detik\")\n",
    "\n",
    "# Tampilkan contoh\n",
    "predictions.select(\"text\", \"model\", \"label\", \"prediction\", \"probability\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e9e8af2-ab8d-4a93-bc5a-7d05091107df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17] Evaluasi...\n",
      "✅ Accuracy    : 0.3667 | Waktu: 1799.2582 detik\n",
      "✅ Precision   : 0.3601 | Waktu: 1647.8974 detik\n",
      "✅ Recall      : 0.3675 | Waktu: 1501.9296 detik\n",
      "✅ F1-score    : 0.3434 | Waktu: 1527.6230 detik\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# --- 6. Evaluasi berbagai metrik ---\n",
    "print(\"[17] Evaluasi...\")\n",
    "\n",
    "# Accuracy\n",
    "evaluator_acc = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy, time_acc = measure_time(lambda: evaluator_acc.evaluate(predictions))\n",
    "\n",
    "# Weighted Precision\n",
    "evaluator_prec = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedPrecision\"\n",
    ")\n",
    "precision, time_prec = measure_time(lambda: evaluator_prec.evaluate(predictions))\n",
    "\n",
    "# Weighted Recall\n",
    "evaluator_rec = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedRecall\"\n",
    ")\n",
    "recall, time_rec = measure_time(lambda: evaluator_rec.evaluate(predictions))\n",
    "\n",
    "# F1-score (weighted)\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "f1_score, time_f1 = measure_time(lambda: evaluator_f1.evaluate(predictions))\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(f\"✅ Accuracy    : {accuracy:.4f} | Waktu: {time_acc:.4f} detik\")\n",
    "print(f\"✅ Precision   : {precision:.4f} | Waktu: {time_prec:.4f} detik\")\n",
    "print(f\"✅ Recall      : {recall:.4f} | Waktu: {time_rec:.4f} detik\")\n",
    "print(f\"✅ F1-score    : {f1_score:.4f} | Waktu: {time_f1:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cd96f-664e-4556-9e94-4e85a8e3bd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5aaf6-7464-45b7-b5e0-e5879294f739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
