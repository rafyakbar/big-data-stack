{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df858680-74bb-4ea1-af85-13d44b70b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.measure_time(func, *args, **kwargs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, when, count as spark_count, concat_ws, length, rand, row_number\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "\n",
    "def measure_time(func, *args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = func(*args, **kwargs)\n",
    "    end = time.perf_counter()\n",
    "    return result, end - start\n",
    "\n",
    "measure_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ebec01-d0e5-4962-a962-9a7bf0b95fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7fdab9226fc3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>RAID-TRAIN</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7854b8858b50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RAID-TRAIN\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65f41de-7158-470f-881d-5be8d90ca3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[adv_source_id: string, attack: string, decoding: string, domain: string, generation: string, id: string, model: string, prompt: string, repetition_penalty: string, source_id: string, title: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(\"hdfs://namenode:8020/user/raid/raw\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e03f8-e75e-4629-90d1-5fe4741d1550",
   "metadata": {},
   "source": [
    "# Total Baris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2426c7bc-e981-4607-8e15-5b237d3e6186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menghitung total jumlah baris...\n",
      "✅ Total baris: 5,615,820 | Waktu: 411.4781 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"Menghitung total jumlah baris...\")\n",
    "total_rows, time_0 = measure_time(lambda: df.count())\n",
    "print(f\"✅ Total baris: {total_rows:,} | Waktu: {time_0:.4f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac9f8a-4d00-42b9-8cad-2156819d2ce4",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330a30a7-0177-4c4f-937d-b8451c4ad239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memfilter data: length(generation) > 50...\n",
      "✅ Filter selesai dalam 0.03 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"Memfilter data: length(generation) > 50...\")\n",
    "df_filtered, filter_time = measure_time(\n",
    "    lambda: df.filter(length(col(\"generation\")) > 50)\n",
    ")\n",
    "\n",
    "print(f\"✅ Filter selesai dalam {filter_time:.2f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4f6769-b6c6-4a2e-aeb9-e0708f4e5285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menghitung total jumlah baris setelah filter...\n",
      "✅ Total baris: 5,610,609 | Waktu: 376.3021 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"Menghitung total jumlah baris setelah filter...\")\n",
    "total_rows, time_1 = measure_time(lambda: df_filtered.count())\n",
    "print(f\"✅ Total baris: {total_rows:,} | Waktu: {time_1:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc6da2b-d537-4a8a-a94c-8fb6bacd0878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[adv_source_id: string, attack: string, decoding: string, domain: string, generation: string, id: string, model: string, prompt: string, repetition_penalty: string, source_id: string, title: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df_filtered.repartition(32)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4001a-8ea9-40c6-920a-f2ddd2c4b7c2",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09ccc2-c47b-4c0a-bc2c-8092d23b4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[1] Total jumlah baris setelah filter...\")\n",
    "print(f\"✅ Total baris: {total_rows:,} | Waktu: {time_1:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e74f80a-6ada-4da2-b653-38a7e95942b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Membuat kolom stratifikasi 'model_domain_attack' ...\n",
      "✅ Kolom stratifikasi dibuat dalam 0.1341 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[2] Membuat kolom stratifikasi 'model_domain_attack' ...\")\n",
    "df_with_strata, strat_time = measure_time(\n",
    "    lambda: df_filtered.withColumn(\n",
    "        \"model_domain_attack\",\n",
    "        concat_ws(\"_\", col(\"model\"), col(\"domain\"), col(\"attack\"))\n",
    "    )\n",
    ")\n",
    "print(f\"✅ Kolom stratifikasi dibuat dalam {strat_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a93e6a-6a0b-418a-a2ca-4f26bf6b1914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[adv_source_id: string, attack: string, decoding: string, domain: string, generation: string, id: string, model: string, prompt: string, repetition_penalty: string, source_id: string, title: string, model_domain_attack: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_strata = df_with_strata.repartition(32)\n",
    "df_with_strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4095181e-ec93-492e-8fe3-337043e20a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Menghitung jumlah baris per 'model_domain_attack' ...\n",
      "✅ Selesai dalam 0.0888 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[3] Menghitung jumlah baris per 'model_domain_attack' ...\")\n",
    "df_counts, count_time = measure_time(\n",
    "    lambda: df_with_strata.groupBy(\"model_domain_attack\").agg(spark_count(\"*\").alias(\"total_per_group\"))\n",
    ")\n",
    "print(f\"✅ Selesai dalam {count_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e0d5a7-28d0-4a89-8b2a-5032ab131382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Gabungkan count ke setiap baris\n",
      "✅ Data berhasil digabung dengan count per grup dalam 0.1788 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[4] Gabungkan count ke setiap baris\")\n",
    "df_joined, join_time = measure_time(\n",
    "    lambda: df_with_strata.join(df_counts, on=\"model_domain_attack\", how=\"inner\")\n",
    ")\n",
    "print(f\"✅ Data berhasil digabung dengan count per grup dalam {join_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167d96f3-209c-4701-94bb-6820bdd3c0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Memberi nomor urut acak dalam setiap grup ...\n",
      "✅ Penomoran selesai dalam 0.0957 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[5] Memberi nomor urut acak dalam setiap grup ...\")\n",
    "window_spec = Window.partitionBy(\"model_domain_attack\").orderBy(rand())\n",
    "df_numbered, number_time = measure_time(\n",
    "    lambda: df_joined.withColumn(\"row_num\", row_number().over(window_spec))\n",
    ")\n",
    "print(f\"✅ Penomoran selesai dalam {number_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79d51c1-b398-410f-b299-28ddbde91364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Menentukan split berdasarkan 70% per grup ...\n",
      "✅ Split logic selesai dalam 0.0655 detik\n"
     ]
    }
   ],
   "source": [
    "# [6] Tentukan batas 70% → masuk train jika row_num <= 0.7 * total_per_group\n",
    "print(\"[6] Menentukan split berdasarkan 70% per grup ...\")\n",
    "df_with_split, split_time = measure_time(\n",
    "    lambda: df_numbered.withColumn(\n",
    "        \"is_train\",\n",
    "        col(\"row_num\") <= (col(\"total_per_group\") * 0.7)\n",
    "    )\n",
    ")\n",
    "print(f\"✅ Split logic selesai dalam {split_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef01815f-f7de-4e86-bf3b-361dcfcf844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Memisahkan train dan test ...\n",
      "✅ Train: 3,926,925 baris (dalam 301.0543 detik)\n",
      "✅ Test:  1,683,684 baris (dalam 308.2308 detik)\n"
     ]
    }
   ],
   "source": [
    "# [7] Pisahkan train dan test\n",
    "print(\"[7] Memisahkan train dan test ...\")\n",
    "train_df = df_with_split.filter(col(\"is_train\")).drop(\"row_num\", \"total_per_group\", \"is_train\")\n",
    "test_df = df_with_split.filter(~col(\"is_train\")).drop(\"row_num\", \"total_per_group\", \"is_train\")\n",
    "\n",
    "train_count, train_time = measure_time(lambda: train_df.count())\n",
    "test_count, test_time = measure_time(lambda: test_df.count())\n",
    "\n",
    "print(f\"✅ Train: {train_count:,} baris (dalam {train_time:.4f} detik)\")\n",
    "print(f\"✅ Test:  {test_count:,} baris (dalam {test_time:.4f} detik)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64cafb1c-d885-406a-ba3e-b69f147cd6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] Menghitung distribusi 'model_domain_attack' di train...\n",
      "[9] Menghitung distribusi 'model_domain_attack' di test...\n",
      "[10] Menggabungkan distribusi train dan test...\n",
      "[11] Mengambil hasil untuk ditampilkan...\n",
      "✅ Berhasil mengambil 1,152 kelas dalam 306.8641 detik\n"
     ]
    }
   ],
   "source": [
    "# [8] Hitung distribusi di train\n",
    "print(\"[8] Menghitung distribusi 'model_domain_attack' di train...\")\n",
    "train_dist = train_df.groupBy(\"model_domain_attack\").count().withColumnRenamed(\"count\", \"train_count\")\n",
    "\n",
    "# [9] Hitung distribusi di test\n",
    "print(\"[9] Menghitung distribusi 'model_domain_attack' di test...\")\n",
    "test_dist = test_df.groupBy(\"model_domain_attack\").count().withColumnRenamed(\"count\", \"test_count\")\n",
    "\n",
    "# [10] Gabungkan train dan test berdasarkan label\n",
    "print(\"[10] Menggabungkan distribusi train dan test...\")\n",
    "from pyspark.sql.functions import coalesce, lit, round as spark_round\n",
    "\n",
    "# Hitung total keseluruhan untuk persentase\n",
    "total_train = train_count\n",
    "total_test = test_count\n",
    "\n",
    "# Join full outer agar semua label muncul (meski hanya di train atau test)\n",
    "combined = train_dist.join(test_dist, on=\"model_domain_attack\", how=\"full_outer\") \\\n",
    "    .fillna(0, subset=[\"train_count\", \"test_count\"])\n",
    "\n",
    "# Urutkan berdasarkan total frekuensi (opsional)\n",
    "combined_sorted = combined.orderBy(col(\"train_count\").desc())\n",
    "\n",
    "# Ambil sebagai Pandas DataFrame untuk tampilan\n",
    "print(\"[11] Mengambil hasil untuk ditampilkan...\")\n",
    "result_pd, fetch_time = measure_time(\n",
    "    lambda: combined_sorted.toPandas()\n",
    ")\n",
    "print(f\"✅ Berhasil mengambil {len(result_pd):,} kelas dalam {fetch_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf782bc-69e0-4604-9502-9de3df63aaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_domain_attack</th>\n",
       "      <th>train_count</th>\n",
       "      <th>test_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama-chat_books_none</td>\n",
       "      <td>4986</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama-chat_books_number</td>\n",
       "      <td>4986</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama-chat_books_upper_lower</td>\n",
       "      <td>4986</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mistral-chat_books_alternative_spelling</td>\n",
       "      <td>4986</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistral-chat_books_none</td>\n",
       "      <td>4986</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>human_reviews_none</td>\n",
       "      <td>660</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>human_reviews_perplexity_misspelling</td>\n",
       "      <td>660</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>human_reviews_number</td>\n",
       "      <td>660</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>human_reviews_upper_lower</td>\n",
       "      <td>660</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>human_reviews_paraphrase</td>\n",
       "      <td>659</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model_domain_attack  train_count  test_count\n",
       "0                       llama-chat_books_none         4986        2138\n",
       "1                     llama-chat_books_number         4986        2138\n",
       "2                llama-chat_books_upper_lower         4986        2138\n",
       "3     mistral-chat_books_alternative_spelling         4986        2138\n",
       "4                     mistral-chat_books_none         4986        2138\n",
       "...                                       ...          ...         ...\n",
       "1147                       human_reviews_none          660         283\n",
       "1148     human_reviews_perplexity_misspelling          660         283\n",
       "1149                     human_reviews_number          660         283\n",
       "1150                human_reviews_upper_lower          660         283\n",
       "1151                 human_reviews_paraphrase          659         283\n",
       "\n",
       "[1152 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9e2f1-9b16-49ea-9841-1967c7542ea6",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bb012e0-16ff-49ea-8d54-a7a7d84227d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame[model_domain_attack: string, adv_source_id: string, attack: string, decoding: string, domain: string, generation: string, id: string, model: string, prompt: string, repetition_penalty: string, source_id: string, title: string],\n",
       " DataFrame[model_domain_attack: string, adv_source_id: string, attack: string, decoding: string, domain: string, generation: string, id: string, model: string, prompt: string, repetition_penalty: string, source_id: string, title: string])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, RegexTokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d47f308-c477-4410-9d96-e706203d58fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12] Menyiapkan kolom 'text' dan 'label_string'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DataFrame[text: string, label_string: string],\n",
       " DataFrame[text: string, label_string: string])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Siapkan hanya kolom teks (label akan diindex) ---\n",
    "print(\"[12] Menyiapkan kolom 'text' dan 'label_string'...\")\n",
    "train_input = train_df.select(\n",
    "    col(\"generation\").alias(\"text\"),\n",
    "    col(\"model\").alias(\"label_string\")\n",
    ")\n",
    "test_input = test_df.select(\n",
    "    col(\"generation\").alias(\"text\"),\n",
    "    col(\"model\").alias(\"label_string\")\n",
    ")\n",
    "\n",
    "train_input = train_input.repartition(128)\n",
    "test_input = test_input.repartition(128)\n",
    "\n",
    "train_input, test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccadc9e4-51ce-4bba-999c-2329e8b62719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13] Membangun pipeline: StringIndexer → TF-IDF → LogisticRegression...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline_0955261d5a10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 2. Bangun pipeline dengan StringIndexer ---\n",
    "print(\"[13] Membangun pipeline: StringIndexer → TF-IDF → LogisticRegression...\")\n",
    "\n",
    "# StringIndexer: string label → numeric (0, 1, 2, ...)\n",
    "string_indexer = StringIndexer(\n",
    "    inputCol=\"label_string\",\n",
    "    outputCol=\"label\",\n",
    "    handleInvalid=\"error\"  # atau \"skip\" jika ada nilai tidak valid\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"text\",\n",
    "    outputCol=\"words\",\n",
    "    pattern=\"\\\\W\"\n",
    ")\n",
    "\n",
    "# Stopwords remover\n",
    "stopwords_remover = StopWordsRemover(\n",
    "    inputCol=\"words\",\n",
    "    outputCol=\"filtered\"\n",
    ")\n",
    "\n",
    "# TF-IDF\n",
    "hashing_tf = HashingTF(\n",
    "    inputCol=\"filtered\",\n",
    "    outputCol=\"raw_features\",\n",
    "    numFeatures=1000\n",
    ")\n",
    "\n",
    "idf = IDF(\n",
    "    inputCol=\"raw_features\",\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Logistic Regression (multinomial)\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    family=\"multinomial\",\n",
    "    regParam=0.1,\n",
    "    maxIter=50\n",
    ")\n",
    "\n",
    "# Pipeline lengkap\n",
    "pipeline = Pipeline(stages=[\n",
    "    string_indexer,\n",
    "    tokenizer,\n",
    "    stopwords_remover,\n",
    "    hashing_tf,\n",
    "    idf,\n",
    "    lr\n",
    "])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0fedd58-33db-49b6-a0ef-29dd29c94cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] Melatih model pada train_input...\n",
      "✅ Model berhasil dilatih dalam 7816.5793 detik\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Latih model ---\n",
    "print(\"[14] Melatih model pada train_input...\")\n",
    "model, train_model_time = measure_time(\n",
    "    lambda: pipeline.fit(train_input)\n",
    ")\n",
    "print(f\"✅ Model berhasil dilatih dalam {train_model_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6df37c9-d9ba-43fd-9867-4a0fbf05ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] Menyimpan model ke HDFS: hdfs://namenode:8020/user/raid/model-tfidf-lr...\n",
      "✅ Model disimpan dalam 13.8640 detik\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Simpan model ke HDFS ---\n",
    "model_path = \"hdfs://namenode:8020/user/raid/model-tfidf-lr\"\n",
    "print(f\"[15] Menyimpan model ke HDFS: {model_path}...\")\n",
    "_, save_time = measure_time(\n",
    "    lambda: model.write().overwrite().save(model_path)\n",
    ")\n",
    "print(f\"✅ Model disimpan dalam {save_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b038104-9d9f-4e5e-abc7-2064c36195e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16] Melakukan prediksi pada test_input...\n",
      "✅ Prediksi selesai dalam 0.18 detik\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Prediksi pada test set ---\n",
    "print(\"[16] Melakukan prediksi pada test_input...\")\n",
    "predictions, predict_time = measure_time(\n",
    "    lambda: model.transform(test_input)\n",
    ")\n",
    "print(f\"✅ Prediksi selesai dalam {predict_time:.2f} detik\")\n",
    "\n",
    "# Tampilkan contoh\n",
    "predictions.select(\"text\", \"label_string\", \"label\", \"prediction\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e8af2-ab8d-4a93-bc5a-7d05091107df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# --- 6. Evaluasi berbagai metrik ---\n",
    "print(\"[17] Evaluasi...\")\n",
    "\n",
    "# Accuracy\n",
    "evaluator_acc = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy, time_acc = measure_time(lambda: evaluator_acc.evaluate(predictions))\n",
    "\n",
    "# Weighted Precision\n",
    "evaluator_prec = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedPrecision\"\n",
    ")\n",
    "precision, time_prec = measure_time(lambda: evaluator_prec.evaluate(predictions))\n",
    "\n",
    "# Weighted Recall\n",
    "evaluator_rec = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedRecall\"\n",
    ")\n",
    "recall, time_rec = measure_time(lambda: evaluator_rec.evaluate(predictions))\n",
    "\n",
    "# F1-score (weighted)\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "f1_score, time_f1 = measure_time(lambda: evaluator_f1.evaluate(predictions))\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(f\"✅ Accuracy    : {accuracy:.4f} | Waktu: {time_acc:.4f} detik\")\n",
    "print(f\"✅ Precision   : {precision:.4f} | Waktu: {time_prec:.4f} detik\")\n",
    "print(f\"✅ Recall      : {recall:.4f} | Waktu: {time_rec:.4f} detik\")\n",
    "print(f\"✅ F1-score    : {f1_score:.4f} | Waktu: {time_f1:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85746fa-ab3d-42fb-9eb6-b22f49d0a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Confusion Matrix (opsional) ---\n",
    "print(\"[18] Menyiapkan confusion matrix...\")\n",
    "\n",
    "# Pastikan label dan prediction bertipe numerik\n",
    "preds_labels = predictions.select(\n",
    "    col(\"prediction\").cast(FloatType()),\n",
    "    col(\"label\").cast(FloatType())\n",
    ").rdd.map(lambda row: (row.prediction, row.label))\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "metrics = MulticlassMetrics(preds_labels)\n",
    "cm = metrics.confusionMatrix().toArray()\n",
    "print(f\"✅ Confusion matrix shape: {cm.shape}\")\n",
    "\n",
    "# Simpan untuk visualisasi\n",
    "import numpy as np\n",
    "np.save(\"/home/jovyan/work/cm_tfidf.npy\", cm)\n",
    "print(\"✅ Confusion matrix disimpan sebagai cm_tfidf.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cd96f-664e-4556-9e94-4e85a8e3bd67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
