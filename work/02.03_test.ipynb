{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896edc36-ba1a-4b31-9d63-600485e53337",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976aef8-a9a8-4232-825e-b82f1dd9ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f70563-76aa-441c-80bc-732c2f641a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.measure_time(func, *args, **kwargs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.feature import StringIndexerModel\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.functions import array_to_vector\n",
    "\n",
    "def measure_time(func, *args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = func(*args, **kwargs)\n",
    "    end = time.perf_counter()\n",
    "    return result, end - start\n",
    "\n",
    "measure_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9cc7d49-99a1-414a-aac4-3ccd3561e194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark session aktif (waktu: 2.4786 detik)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1️⃣ Setup Spark Session\n",
    "# ------------------------------------------------------------\n",
    "spark, t_spark = measure_time(\n",
    "    lambda: SparkSession.builder\n",
    "        .appName(\"RAID-INFERENCE\")\n",
    "        .master(\"spark://spark-master:7077\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "print(f\"✅ Spark session aktif (waktu: {t_spark:.4f} detik)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17057ebe-caa8-43c9-919f-1a6c84cf8543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark session aktif (waktu: 1.7506 detik)\n"
     ]
    }
   ],
   "source": [
    "spark, time_spark = measure_time(\n",
    "    lambda: SparkSession.builder\n",
    "        .appName(\"RAID-INFERENCE\")\n",
    "        .master(\"local[*]\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "print(f\"✅ Spark session aktif (waktu: {time_spark:.4f} detik)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a728f09c-ce36-40b2-a995-68cac316f396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Path absolut model: /home/jovyan/work/backup_model-sbert-lr_human-gpt4\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = os.path.abspath(\"backup_model-sbert-lr_human-gpt4\")\n",
    "print(f\"[DEBUG] Path absolut model: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812d6196-d283-4c01-a4cd-cdc5f1ca0391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Memuat model dari lokal: /home/jovyan/work/backup_model-sbert-lr_human-gpt4 ...\n",
      "✅ Model berhasil dimuat dalam 4.2590 detik.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2️⃣ Load Pretrained Model dari Direktori Lokal\n",
    "# ------------------------------------------------------------\n",
    "print(f\"[2] Memuat model dari lokal: {MODEL_PATH} ...\")\n",
    "model, time_model = measure_time(lambda: PipelineModel.load(MODEL_PATH))\n",
    "print(f\"✅ Model berhasil dimuat dalam {time_model:.4f} detik.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4042dba3-989f-4df1-b590-140fef0a36e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Memuat tokenizer & model MiniLM untuk ekstraksi fitur...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3ab63a664e43e4920297ec65ecf40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0db13e596964050a22a4ed7cc942b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aee55dfee2041e6809d539eb1e3590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8fe36ec2214976b6c0454667a8d530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac8d7ba1dd9435dbc12ca655909787a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfcbff133a0467fa7bf0d8e7999a792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MiniLM siap dalam 12.1216 detik (device: cpu).\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3️⃣ Load Sentence Transformer (MiniLM)\n",
    "# ------------------------------------------------------------\n",
    "print(\"[3] Memuat tokenizer & model MiniLM untuk ekstraksi fitur...\")\n",
    "\n",
    "def load_miniLM():\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    encoder = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    encoder.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    encoder.to(device)\n",
    "    return tokenizer, encoder, device\n",
    "\n",
    "(tokenizer, encoder, device), time_minilm = measure_time(load_miniLM)\n",
    "print(f\"✅ MiniLM siap dalam {time_minilm:.4f} detik (device: {device}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706a2ea8-26f1-43bd-ba62-5d5a9e785602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_embedding(text: str)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4️⃣ Fungsi get_embedding()\n",
    "# ------------------------------------------------------------\n",
    "def get_embedding(text: str):\n",
    "    \"\"\"Ekstraksi embedding 384-dimensi dari teks menggunakan MiniLM\"\"\"\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return [0.0] * 384\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        max_length=512\n",
    "    )\n",
    "    encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "    with torch.no_grad():\n",
    "        output = encoder(**encoded)\n",
    "    token_embeddings = output.last_hidden_state\n",
    "    attention_mask = encoded['attention_mask']\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings.cpu().numpy()[0].tolist()\n",
    "get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b023ab0-31ca-47f1-803a-035dbbe5f680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.classify_text(text: str)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5️⃣ Fungsi classify_text(text)\n",
    "# ------------------------------------------------------------\n",
    "def classify_text(text: str):\n",
    "    # [a] Embedding\n",
    "    emb, time_emb = measure_time(lambda: get_embedding(text))\n",
    "\n",
    "    # [b] Konversi ke Spark DataFrame\n",
    "    df, time_df = measure_time(lambda: spark.createDataFrame([Row(features=Vectors.dense(emb))]))\n",
    "\n",
    "    # [c] Prediksi\n",
    "    pred_row, time_pred = measure_time(lambda: model.transform(df).select(\"prediction\", \"probability\").collect()[0])\n",
    "\n",
    "    # [d] Interpretasi hasil\n",
    "    label_indexer = model.stages[0]  # StringIndexer pertama dalam pipeline\n",
    "    labels = label_indexer.labels    # contoh: ['gpt4', 'human']\n",
    "\n",
    "    predicted_index = int(pred_row['prediction'])\n",
    "    predicted_label = labels[predicted_index]\n",
    "    prob_vector = pred_row['probability']\n",
    "    prob_dict = {labels[i]: float(prob_vector[i]) for i in range(len(labels))}\n",
    "\n",
    "    time_total = time_emb + time_df + time_pred\n",
    "\n",
    "    return {\n",
    "        \"input_text\": text[:100] + (\"...\" if len(text) > 100 else \"\"),\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"probabilities\": prob_dict,\n",
    "        \"timing\": {\n",
    "            \"embedding\": round(time_emb, 4),\n",
    "            \"dataframe\": round(time_df, 4),\n",
    "            \"prediction\": round(time_pred, 4),\n",
    "            \"total\": round(time_total, 4)\n",
    "        }\n",
    "    }\n",
    "\n",
    "classify_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c30348-676e-4150-b120-25eedd87ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Menguji teks GPT-4...\n",
      "✅ Selesai dalam 0.2648 detik\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_text': 'The sun dipped below the horizon, painting the sky with hues of amber and rose.',\n",
       " 'predicted_label': 'gpt4',\n",
       " 'probabilities': {'gpt4': 0.8959879081761304, 'human': 0.1040120918238696},\n",
       " 'timing': {'embedding': 0.0067,\n",
       "  'dataframe': 0.0155,\n",
       "  'prediction': 0.2405,\n",
       "  'total': 0.2626}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 52352)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6️⃣ Contoh Pengujian\n",
    "# ------------------------------------------------------------\n",
    "sample_text_gpt4 = \"The sun dipped below the horizon, painting the sky with hues of amber and rose.\"\n",
    "\n",
    "print(\"[6] Menguji teks GPT-4...\")\n",
    "result_gpt4, time_gpt4 = measure_time(lambda: classify_text(sample_text_gpt4))\n",
    "print(f\"✅ Selesai dalam {time_gpt4:.4f} detik\\n\")\n",
    "\n",
    "result_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f463d8-1e4a-40f2-b5e1-5a01ff389a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
