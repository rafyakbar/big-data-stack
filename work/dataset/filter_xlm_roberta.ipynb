{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb5484-ab99-4626-9688-e8a2e6554a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets tqdm --upgrade\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcfd78b-6716-4a2e-89b1-c53a6bf529f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function __main__.extract_text_feature(text, model_name='FacebookAI/xlm-roberta-base', model=None, tokenizer_name='FacebookAI/xlm-roberta-base', tokenizer=None, device=None)>,\n",
       " 'cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "def extract_text_feature(\n",
    "    text,\n",
    "    model_name=\"FacebookAI/xlm-roberta-base\",\n",
    "    model=None,\n",
    "    tokenizer_name=\"FacebookAI/xlm-roberta-base\",\n",
    "    tokenizer=None,\n",
    "    device=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Mengekstraksi fitur embedding dari teks menggunakan model Transformer seperti XLM-RoBERTa.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str atau list[str]\n",
    "        Input teks tunggal atau daftar teks.\n",
    "    model_name : str, optional\n",
    "        Nama model pretrained dari Hugging Face (default: \"FacebookAI/xlm-roberta-base\").\n",
    "    model : transformers.AutoModel, optional\n",
    "        Objek model yang sudah dimuat (agar tidak load ulang).\n",
    "    tokenizer_name : str, optional\n",
    "        Nama tokenizer pretrained (default: sama seperti model_name).\n",
    "    tokenizer : transformers.AutoTokenizer, optional\n",
    "        Objek tokenizer yang sudah dimuat.\n",
    "    device : str, optional\n",
    "        'cpu' atau 'cuda'. Jika None, otomatis deteksi GPU bila tersedia.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Matriks embedding berdimensi [n_texts, hidden_size].\n",
    "    \"\"\"\n",
    "\n",
    "    # Pastikan input berbentuk list\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "\n",
    "    # Deteksi device otomatis\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load tokenizer jika belum ada\n",
    "    if tokenizer is None:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    # Load model jika belum ada\n",
    "    if model is None:\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenisasi input\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state  # [batch, seq_len, hidden_size]\n",
    "\n",
    "        # Mean pooling (dengan masking)\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        masked_embeddings = last_hidden_state * attention_mask.unsqueeze(-1)\n",
    "        sentence_embeddings = masked_embeddings.sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Pindahkan ke numpy\n",
    "    embeddings = sentence_embeddings.cpu().numpy()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "extract_text_feature, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd878fc-175b-45e8-b956-f712cc4d36a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FacebookAI/xlm-roberta-base'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"FacebookAI/xlm-roberta-base\"\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d425649-f598-4f7f-9982-2687c91681ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 09:12:38.206456: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-05 09:12:38.242139: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-05 09:12:39.106747: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): XLMRobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): XLMRobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): XLMRobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f88c7c2-cd21-4109-a8f0-7af8c13b83e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaTokenizerFast(name_or_path='FacebookAI/xlm-roberta-base', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e74ec2-cc41-4b1c-bf3d-f786c4cfa9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "embeddings = extract_text_feature('This is a story about rafy aa!', model=model, tokenizer=tokenizer)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "775a0b89-8594-4cb6-93a8-54a00cb67d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train.csv',\n",
       " 'raid_xlm-roberta_human-gpt4.jsonl',\n",
       " ['human', 'gpt4'],\n",
       " 'generation',\n",
       " 'model',\n",
       " 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = \"train.csv\"\n",
    "output_file = \"raid_xlm-roberta_human-gpt4.jsonl\"\n",
    "filtered_models = ['human', 'gpt4']\n",
    "text_column = \"generation\"\n",
    "model_column = \"model\"\n",
    "chunksize = 1\n",
    "\n",
    "input_file, output_file, filtered_models, text_column, model_column, chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c605e8-aefe-459d-9335-6ef7fb4e9506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memproses file besar (11.78 GB): train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|█████████████████████████████████████████████████████████████████| 11.8G/11.8G [3:39:50<00:00, 893kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Selesai! Total 481,356 baris disimpan ke raid_xlm-roberta_human-gpt4.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Hitung ukuran file untuk progress bar ===\n",
    "total_size = os.path.getsize(input_file)\n",
    "print(f\"Memproses file besar ({total_size / 1e9:.2f} GB): {input_file}\")\n",
    "\n",
    "# === Buat file output kosong ===\n",
    "open(output_file, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "progress = tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Extracting\", dynamic_ncols=True)\n",
    "count = 0\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as out_file:\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        reader = pd.read_csv(f, chunksize=chunksize)\n",
    "        last_pos = 0\n",
    "\n",
    "        for chunk in reader:\n",
    "            current_pos = f.tell()\n",
    "            progress.update(current_pos - last_pos)\n",
    "            last_pos = current_pos\n",
    "\n",
    "            # Filter model target\n",
    "            filtered = chunk[chunk[model_column].isin(filtered_models)]\n",
    "\n",
    "            if not filtered.empty:\n",
    "                for _, row in filtered.iterrows():\n",
    "                    text = str(row[text_column])\n",
    "                    features = extract_text_feature(\n",
    "                        text,\n",
    "                        model=model,\n",
    "                        tokenizer=tokenizer,\n",
    "                        device=device\n",
    "                    )[0].tolist()\n",
    "\n",
    "                    record = {\n",
    "                        \"id\": row.get(\"id\", None),\n",
    "                        \"model\": row[model_column],\n",
    "                        \"domain\": row.get(\"domain\", None),\n",
    "                        \"attack\": row.get(\"attack\", None),\n",
    "                        \"generation\": text,\n",
    "                        \"features\": features\n",
    "                    }\n",
    "\n",
    "                    out_file.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "                    \n",
    "                    count += 1\n",
    "\n",
    "progress.close()\n",
    "print(f\"\\n✅ Selesai! Total {count:,} baris disimpan ke {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef77390-8603-4ab5-a813-484118732e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
