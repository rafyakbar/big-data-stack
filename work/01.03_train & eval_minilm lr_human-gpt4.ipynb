{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df858680-74bb-4ea1-af85-13d44b70b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.measure_time(func, *args, **kwargs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc, when, count as spark_count, concat_ws, length, rand, row_number\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def measure_time(func, *args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = func(*args, **kwargs)\n",
    "    end = time.perf_counter()\n",
    "    return result, end - start\n",
    "\n",
    "measure_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ebec01-d0e5-4962-a962-9a7bf0b95fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7fdab9226fc3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>RAID-TRAIN</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x715375bfd990>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RAID-TRAIN\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65f41de-7158-470f-881d-5be8d90ca3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[attack: string, domain: string, features: array<double>, generation: string, id: string, model: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(\"hdfs://namenode:8020/user/raid/filtered_minilm\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e03f8-e75e-4629-90d1-5fe4741d1550",
   "metadata": {},
   "source": [
    "# Total Baris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2426c7bc-e981-4607-8e15-5b237d3e6186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menghitung total jumlah baris...\n",
      "✅ Total baris: 1,869,542 | Waktu: 287.7117 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"Menghitung total jumlah baris...\")\n",
    "total_rows, time_0 = measure_time(lambda: df.count())\n",
    "print(f\"✅ Total baris: {total_rows:,} | Waktu: {time_0:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8848b761-183b-489f-bc7b-acbe6fd89ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memfilter data: model IN ('human', 'gpt4')...\n",
      "✅ Filter selesai dalam 0.0368 detik\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, length\n",
    "\n",
    "# Filter: (1) panjang teks > 50, DAN (2) model hanya 'human' atau 'gpt4'\n",
    "print(\"Memfilter data: model IN ('human', 'gpt4')...\")\n",
    "df_filtered, filter_time = measure_time(\n",
    "    lambda: df.filter(\n",
    "        (col(\"model\").isin([\"human\", \"gpt4\"]))\n",
    "    )\n",
    ")\n",
    "print(f\"✅ Filter selesai dalam {filter_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc6da2b-d537-4a8a-a94c-8fb6bacd0878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[attack: string, domain: string, features: array<double>, generation: string, id: string, model: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df_filtered.repartition(128)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4001a-8ea9-40c6-920a-f2ddd2c4b7c2",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee09ccc2-c47b-4c0a-bc2c-8092d23b4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Menghitung total jumlah baris...\n",
      "✅ Total baris: 160,390 | Waktu: 272.7278 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[1] Menghitung total jumlah baris...\")\n",
    "total_rows, time_0 = measure_time(lambda: df_filtered.count())\n",
    "print(f\"✅ Total baris: {total_rows:,} | Waktu: {time_0:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e74f80a-6ada-4da2-b653-38a7e95942b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Membuat kolom stratifikasi 'model_domain_attack' ...\n",
      "✅ Kolom stratifikasi dibuat dalam 0.0233 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[2] Membuat kolom stratifikasi 'model_domain_attack' ...\")\n",
    "df_with_strata, strat_time = measure_time(\n",
    "    lambda: df_filtered.withColumn(\n",
    "        \"model_domain_attack\",\n",
    "        concat_ws(\"_\", col(\"model\"), col(\"domain\"), col(\"attack\"))\n",
    "    )\n",
    ")\n",
    "print(f\"✅ Kolom stratifikasi dibuat dalam {strat_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a93e6a-6a0b-418a-a2ca-4f26bf6b1914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[attack: string, domain: string, features: array<double>, generation: string, id: string, model: string, model_domain_attack: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_strata = df_with_strata.repartition(32)\n",
    "df_with_strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4095181e-ec93-492e-8fe3-337043e20a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Menghitung jumlah baris per 'model_domain_attack' ...\n",
      "✅ Selesai dalam 0.0443 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[3] Menghitung jumlah baris per 'model_domain_attack' ...\")\n",
    "df_counts, count_time = measure_time(\n",
    "    lambda: df_with_strata.groupBy(\"model_domain_attack\").agg(spark_count(\"*\").alias(\"total_per_group\"))\n",
    ")\n",
    "print(f\"✅ Selesai dalam {count_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e0d5a7-28d0-4a89-8b2a-5032ab131382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Gabungkan count ke setiap baris\n",
      "✅ Data berhasil digabung dengan count per grup dalam 0.1141 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[4] Gabungkan count ke setiap baris\")\n",
    "df_joined, join_time = measure_time(\n",
    "    lambda: df_with_strata.join(df_counts, on=\"model_domain_attack\", how=\"inner\")\n",
    ")\n",
    "print(f\"✅ Data berhasil digabung dengan count per grup dalam {join_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167d96f3-209c-4701-94bb-6820bdd3c0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Memberi nomor urut acak dalam setiap grup ...\n",
      "✅ Penomoran selesai dalam 0.0452 detik\n"
     ]
    }
   ],
   "source": [
    "print(\"[5] Memberi nomor urut acak dalam setiap grup ...\")\n",
    "window_spec = Window.partitionBy(\"model_domain_attack\").orderBy(rand())\n",
    "df_numbered, number_time = measure_time(\n",
    "    lambda: df_joined.withColumn(\"row_num\", row_number().over(window_spec))\n",
    ")\n",
    "print(f\"✅ Penomoran selesai dalam {number_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79d51c1-b398-410f-b299-28ddbde91364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Menentukan split berdasarkan 70% per grup ...\n",
      "✅ Split logic selesai dalam 0.0845 detik\n"
     ]
    }
   ],
   "source": [
    "# [6] Tentukan batas 70% → masuk train jika row_num <= 0.7 * total_per_group\n",
    "print(\"[6] Menentukan split berdasarkan 70% per grup ...\")\n",
    "df_with_split, split_time = measure_time(\n",
    "    lambda: df_numbered.withColumn(\n",
    "        \"is_train\",\n",
    "        col(\"row_num\") <= (col(\"total_per_group\") * 0.7)\n",
    "    )\n",
    ")\n",
    "print(f\"✅ Split logic selesai dalam {split_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef01815f-f7de-4e86-bf3b-361dcfcf844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train: 112,247 (295.9162 detik) | Test: 48,143 (276.8737 detik)\n"
     ]
    }
   ],
   "source": [
    "# [7] Pisahkan train dan test\n",
    "# train_df = df_with_split.filter(col(\"is_train\")).select(\"model\", \"features\")\n",
    "# test_df = df_with_split.filter(~col(\"is_train\")).select(\"model\", \"features\")\n",
    "\n",
    "train_df = df_with_split.filter(col(\"is_train\")).select(\n",
    "    col(\"generation\").alias(\"text\"),\n",
    "    col(\"model\"),\n",
    "    col(\"features\")\n",
    ")\n",
    "test_df = df_with_split.filter(~col(\"is_train\")).select(\n",
    "    col(\"generation\").alias(\"text\"),\n",
    "    col(\"model\"),\n",
    "    col(\"features\")\n",
    ")\n",
    "\n",
    "train_count, train_count_time = measure_time(lambda: train_df.count())\n",
    "test_count, test_count_time = measure_time(lambda: test_df.count())\n",
    "\n",
    "print(f\"✅ Train: {train_count:,} ({train_count_time:.4f} detik) | Test: {test_count:,} ({test_count_time:.4f} detik)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7830da8f-23a8-42d9-9949-a3b748d954d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.functions import array_to_vector\n",
    "\n",
    "train_df = train_df.withColumn(\"features\", array_to_vector(col(\"features\")))\n",
    "test_df = test_df.withColumn(\"features\", array_to_vector(col(\"features\")))\n",
    "\n",
    "# Opsional: cek tipe kolom\n",
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9e2f1-9b16-49ea-9841-1967c7542ea6",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb012e0-16ff-49ea-8d54-a7a7d84227d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame[text: string, model: string, features: vector],\n",
       " DataFrame[text: string, model: string, features: vector])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab3cf4ff-4929-4eec-866a-32fa959a7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membangun pipeline...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline_8b24ecad31a5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Pipeline: StringIndexer + LogisticRegression ===\n",
    "print(\"Membangun pipeline...\")\n",
    "\n",
    "# StringIndexer untuk label 'model'\n",
    "string_indexer = StringIndexer(\n",
    "    inputCol=\"model\",\n",
    "    outputCol=\"label\",\n",
    "    handleInvalid=\"error\"\n",
    ")\n",
    "\n",
    "# Logistic Regression langsung pada fitur numerik (384-d)\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    family=\"multinomial\",\n",
    "    regParam=0.01,      # regularisasi ringan\n",
    "    maxIter=100,\n",
    "    tol=1e-6\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[string_indexer, lr])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0fedd58-33db-49b6-a0ef-29dd29c94cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] Melatih model pada train_df...\n",
      "✅ Model berhasil dilatih dalam 2929.5631 detik\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Latih model ---\n",
    "print(\"[14] Melatih model pada train_df...\")\n",
    "model, train_model_time = measure_time(\n",
    "    lambda: pipeline.fit(train_df)\n",
    ")\n",
    "print(f\"✅ Model berhasil dilatih dalam {train_model_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6df37c9-d9ba-43fd-9867-4a0fbf05ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] Menyimpan model ke HDFS: hdfs://namenode:8020/user/raid/model-sbert-lr_human-gpt4...\n",
      "✅ Model disimpan dalam 9.8552 detik\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Simpan model ke HDFS ---\n",
    "model_path = \"hdfs://namenode:8020/user/raid/model-sbert-lr_human-gpt4\"\n",
    "print(f\"[15] Menyimpan model ke HDFS: {model_path}...\")\n",
    "_, save_time = measure_time(\n",
    "    lambda: model.write().overwrite().save(model_path)\n",
    ")\n",
    "print(f\"✅ Model disimpan dalam {save_time:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b038104-9d9f-4e5e-abc7-2064c36195e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16] Melakukan prediksi pada test_df...\n",
      "✅ Prediksi selesai dalam 0.0449 detik\n",
      "+--------------------------------------------------+-----+-----+----------+----------------------------------------+\n",
      "|                                              text|model|label|prediction|                             probability|\n",
      "+--------------------------------------------------+-----+-----+----------+----------------------------------------+\n",
      "|Ingredients:\\n\\nFor the Crust:\\n- 1 1/2 cups gr...| gpt4|  0.0|       0.0|[0.8912502556999004,0.10874974430009975]|\n",
      "|Ingredients:\\n\\nFor Bread:\\n\\n- 1 loaf of crust...| gpt4|  0.0|       0.0|[0.9163321063701791,0.08366789362982094]|\n",
      "|Ingredients:\\n\\n- 1 whole turkey (about 3-4 kil...| gpt4|  0.0|       0.0|  [0.858609713005238,0.1413902869947619]|\n",
      "|ingredients:\\n\\n- 2 everything bagels\\n- 4 slic...| gpt4|  0.0|       0.0|[0.9353020594723525,0.06469794052764764]|\n",
      "|ingredients:\\n\\n- 2 pork tenderloins (about 1 o...| gpt4|  0.0|       0.0|[0.8457616500697258,0.15423834993027424]|\n",
      "+--------------------------------------------------+-----+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Prediksi pada test set ---\n",
    "print(\"[16] Melakukan prediksi pada test_df...\")\n",
    "predictions, predict_time = measure_time(\n",
    "    lambda: model.transform(test_df)\n",
    ")\n",
    "print(f\"✅ Prediksi selesai dalam {predict_time:.4f} detik\")\n",
    "\n",
    "# Tampilkan contoh\n",
    "predictions.select(\"text\", \"model\", \"label\", \"prediction\", \"probability\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e9e8af2-ab8d-4a93-bc5a-7d05091107df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17] Evaluasi...\n",
      "✅ Accuracy    : 0.8791 | Waktu: 636.8524 detik\n",
      "✅ Precision   : 0.8766 | Waktu: 645.7478 detik\n",
      "✅ Recall      : 0.8789 | Waktu: 675.2073 detik\n",
      "✅ F1-score    : 0.8765 | Waktu: 640.6882 detik\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# --- 6. Evaluasi berbagai metrik ---\n",
    "print(\"[17] Evaluasi...\")\n",
    "\n",
    "# Accuracy\n",
    "evaluator_acc = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "accuracy, time_acc = measure_time(lambda: evaluator_acc.evaluate(predictions))\n",
    "\n",
    "# Weighted Precision\n",
    "evaluator_prec = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedPrecision\"\n",
    ")\n",
    "precision, time_prec = measure_time(lambda: evaluator_prec.evaluate(predictions))\n",
    "\n",
    "# Weighted Recall\n",
    "evaluator_rec = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedRecall\"\n",
    ")\n",
    "recall, time_rec = measure_time(lambda: evaluator_rec.evaluate(predictions))\n",
    "\n",
    "# F1-score (weighted)\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "f1_score, time_f1 = measure_time(lambda: evaluator_f1.evaluate(predictions))\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(f\"✅ Accuracy    : {accuracy:.4f} | Waktu: {time_acc:.4f} detik\")\n",
    "print(f\"✅ Precision   : {precision:.4f} | Waktu: {time_prec:.4f} detik\")\n",
    "print(f\"✅ Recall      : {recall:.4f} | Waktu: {time_rec:.4f} detik\")\n",
    "print(f\"✅ F1-score    : {f1_score:.4f} | Waktu: {time_f1:.4f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cd96f-664e-4556-9e94-4e85a8e3bd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5aaf6-7464-45b7-b5e0-e5879294f739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
